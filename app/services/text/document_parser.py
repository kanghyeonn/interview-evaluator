from google.cloud import documentai
from google.cloud import storage
from prettytable import PrettyTable
import google.generativeai as genai
import re
import os
import json
import hashlib
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path
from app.services.extrack.hwpx_extractor import hwpx_to_html
from app.services.extrack.docx_extractor import extract_text_from_docx


from dotenv import load_dotenv
import os

load_dotenv()


gemini_api_key = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=gemini_api_key)

project_id = os.getenv("PROJECT_ID")
processor_id = os.getenv("PROCESSOR_ID")
location = os.getenv("LOCATION", "us")
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')

class VertexDocumentParser:
    """Vertex AI Document AIì™€ Geminië¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ íŒŒì‹± ë° êµ¬ì¡°í™” í´ëž˜ìŠ¤"""

    def __init__(self, project_id: str, location: str, processor_id: str, gemini_api_key: str):
        self.processor_name = f"projects/{project_id}/locations/{location}/processors/{processor_id}"
        self.client = documentai.DocumentProcessorServiceClient()
        self.storage_path = "parsed_documents/"

        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')

        os.makedirs(self.storage_path, exist_ok=True)

    def parse_document(self, file_path: str) -> Dict[str, Any]:
        """
        ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ë°˜í™˜
        ì§€ì› í˜•ì‹: PDF, HWPX, DOCX
        """
        file_path = Path(file_path)
        text = ""

        # 1. PDF or ì´ë¯¸ì§€ íŒŒì¼ â†’ Document AI ì‚¬ìš©
        if file_path.suffix.lower() in ['.pdf', '.jpg', '.jpeg', '.png']:
            with open(file_path, "rb") as f:
                file_content = f.read()

            mime_type = "application/pdf" if file_path.suffix.lower() == ".pdf" else "image/jpeg"

            result = self.client.process_document(
                request=documentai.ProcessRequest(
                    name=self.processor_name,
                    raw_document=documentai.RawDocument(
                        content=file_content,
                        mime_type=mime_type
                    )
                )
            )
            text = result.document.text
            page_count = len(result.document.pages)

        # 2. HWPX íŒŒì¼
        elif file_path.suffix.lower() == ".hwpx":
            text = hwpx_to_html(str(file_path))
            page_count = 1  # ì¶”ì •ê°’, í•„ìš” ì‹œ ë³´ì™„

        # 3. DOCX íŒŒì¼
        elif file_path.suffix.lower() == ".docx":
            text = extract_text_from_docx(str(file_path))
            page_count = 1

        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ìž…ë‹ˆë‹¤: {file_path.suffix}")

        # 4. Geminië¡œ êµ¬ì¡°í™”
        structured_data = self._structure_with_gemini(text)

        return {
            "full_text": text,
            "pages": page_count,
            "structured_content": structured_data
        }

    def _structure_with_gemini(self, text: str) -> Dict[str, Any]:
        """Geminië¥¼ ì‚¬ìš©í•´ì„œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ë§Œ ìžë™ êµ¬ì¡°í™”"""
        prompt = f"""
        ë‹¤ìŒ ì´ë ¥ì„œ/ìžê¸°ì†Œê°œì„œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ì— í•„ìš”í•œ ì •ë³´ë§Œ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”.
        ê°œì¸ ì‹ë³„ ì •ë³´(ì´ë¦„, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼, ì£¼ì†Œ)ëŠ” ì œì™¸í•˜ê³  ì¶”ì¶œí•˜ì„¸ìš”.

        í…ìŠ¤íŠ¸:
        {text}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
        {{
            "education": {{
                "school": "í•™êµëª…",
                "major": "ì „ê³µ",
                "period": "ìž¬í•™ê¸°ê°„",
                "gpa": "í•™ì "
            }},
            "skills": ["ê¸°ìˆ 1", "ê¸°ìˆ 2", ...],
            "certifications": ["ìžê²©ì¦1", "ìžê²©ì¦2", ...],
            "career": {{
                "status": "ì‹ ìž…/ê²½ë ¥",
                "experience": "ê²½ë ¥ ìƒì„¸ (ìžˆëŠ” ê²½ìš°)",
                "years": "ê²½ë ¥ ë…„ìˆ˜"
            }},
            "projects": [
                {{
                    "name": "í”„ë¡œì íŠ¸ëª…",
                    "description": "ì„¤ëª…",
                    "tech_stack": ["ì‚¬ìš© ê¸°ìˆ "],
                    "period": "ê¸°ê°„"
                }}
            ],
            "desired_position": {{
                "location": "í¬ë§ê·¼ë¬´ì§€",
                "salary": "í¬ë§ì—°ë´‰",
                "job_type": "í¬ë§ ì§ë¬´",
                "industry": "í¬ë§ ì‚°ì—…ë¶„ì•¼"
            }},
            "self_introduction": {{
                "motivation": "ì§€ì›ë™ê¸°",
                "strengths": "ê°•ì ",
                "career_goals": "ëª©í‘œ",
                "key_experiences": "ì£¼ìš” ê²½í—˜"
            }}
        }}

        JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
        ì •ë³´ê°€ ì—†ëŠ” í•„ë“œëŠ” null ë˜ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”.
        """

        response = self.gemini_model.generate_content(prompt)

        try:
            cleaned = self._strip_code_block(response.text)
            return json.loads(cleaned)
        except Exception as e:
            print("âŒ Gemini ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("ðŸ“„ ì›ë³¸ ì‘ë‹µ:\n", response.text)
            raise e

    @staticmethod
    def _strip_code_block(text: str) -> str:
        """Geminiê°€ ```json ... ``` í˜•íƒœë¡œ ê°ì‹¼ ì‘ë‹µ ì œê±°"""
        return re.sub(r"^```(?:json)?\n?|```$", "", text.strip(), flags=re.MULTILINE)

    def save_parsed_data(self, file_path: str, parsed_data: Dict[str, Any]) -> str:
        """íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ì €ìž¥í•˜ê³  ë¬¸ì„œ ID ë°˜í™˜"""
        doc_id = hashlib.md5(file_path.encode()).hexdigest()[:12]

        save_path = os.path.join(self.storage_path, f"{doc_id}.json")
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump({
                "doc_id": doc_id,
                "original_file": os.path.basename(file_path),
                "parsed_at": datetime.now().isoformat(),
                "data": parsed_data
            }, f, ensure_ascii=False, indent=2)

        return doc_id

    def parse_and_save(self, file_path: str) -> str:
        """ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  ì €ìž¥í•˜ëŠ” í†µí•© ë©”ì„œë“œ"""
        parsed = self.parse_document(file_path)
        return self.save_parsed_data(file_path, parsed)
